{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOV3目标检测-视频逐帧处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同济子豪兄：https://space.bilibili.com/1900783\n",
    "\n",
    "不注明出处的转载视为侵权。\n",
    "\n",
    "2021-08-28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入工具包和模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\r\n",
    "import numpy as np\r\n",
    "from tqdm import tqdm\r\n",
    "\r\n",
    "# 导入预训练YOLOV3模型\r\n",
    "net = cv2.dnn.readNet('yolov3.weights','yolov3.cfg')\r\n",
    "# 获取三个尺度输出层的名称\r\n",
    "layersNames = net.getLayerNames()\r\n",
    "# output_layers_names = [layersNames[i[0] - 1] for i in net.getUnconnectedOutLayers()]\r\n",
    "output_layers_names =  [layersNames[i-1] for i in net.getUnconnectedOutLayers()]\r\n",
    "\r\n",
    "# 导入COCO数据集80个类别\r\n",
    "with open('coco.names','r') as f:\r\n",
    "    classes = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CONF_THRES = 0.03 # 指定置信度阈值，阈值越大，置信度过滤越强\n",
    "NMS_THRES = 0.4 # 指定NMS阈值，阈值越小，NMS越强"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理单帧的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理帧函数\n",
    "def process_frame(img):\n",
    "    # 获取图像宽高\n",
    "    height, width, _ = img.shape\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (416,416), (0,0,0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    # 前向推断\n",
    "    prediction = net.forward(output_layers_names)\n",
    "\n",
    "    # 从三个尺度输出结果中解析所有预测框信息\n",
    "    # 存放预测框坐标\n",
    "    boxes = []\n",
    "    # 存放置信度\n",
    "    objectness = []\n",
    "    # 存放类别概率\n",
    "    class_probs = []\n",
    "    # 存放预测框类别索引号\n",
    "    class_ids = []\n",
    "    # 存放预测框类别名称\n",
    "    class_names = []\n",
    "\n",
    "    for scale in prediction: # 遍历三种尺度\n",
    "        for bbox in scale: # 遍历每个预测框\n",
    "            obj = bbox[4] # 获取该预测框的confidence（objectness）\n",
    "            class_scores = bbox[5:] # 获取该预测框在COCO数据集80个类别的概率\n",
    "            class_id = np.argmax(class_scores) # 获取概率最高类别的索引号\n",
    "            class_name = classes[class_id] # 获取概率最高类别的名称\n",
    "            class_prob = class_scores[class_id] # 获取概率最高类别的概率\n",
    "\n",
    "            # 获取预测框中心点坐标、预测框宽高\n",
    "            center_x = int(bbox[0] * width)\n",
    "            center_y = int(bbox[1] * height)\n",
    "            w = int(bbox[2] * width)\n",
    "            h = int(bbox[3] * height)\n",
    "            # 计算预测框左上角坐标\n",
    "            x = int(center_x - w/2)\n",
    "            y = int(center_y - h/2)\n",
    "\n",
    "            # 将每个预测框的结果存放至上面的列表中\n",
    "            boxes.append([x, y, w, h])\n",
    "            objectness.append(float(obj))\n",
    "            class_ids.append(class_id)\n",
    "            class_names.append(class_name)\n",
    "            class_probs.append(class_prob)\n",
    "            \n",
    "    # 将预测框置信度objectness与各类别置信度class_pred相乘，获得最终该预测框的置信度confidence\n",
    "    confidences = np.array(class_probs) * np.array(objectness)\n",
    "\n",
    "    # 置信度过滤、非极大值抑制抑制NMS\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, CONF_THRES, NMS_THRES)\n",
    "    # 随机给每个预测框生成一种颜色\n",
    "    colors = [[255,0,255],[0,0,255],[0,255,255],[0,255,0],[255,255,0],[255,0,0],[180,187,28],[223,155,6],[94,218,121],[139,0,0],[77,169,10],[29,123,243],[66,77,229],[1,240,255],[140,47,240],[31,41,81],[29,123,243],[16,144,247],[151,57,224]]\n",
    "\n",
    "    # 遍历留下的每一个预测框，可视化\n",
    "    for i in indexes.flatten():\n",
    "        # 获取坐标\n",
    "        x, y, w, h = boxes[i]\n",
    "        # 获取置信度\n",
    "        confidence = str(round(confidences[i],2))\n",
    "        # 获取颜色，画框\n",
    "        color = colors[i%len(colors)]\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), color, 5)\n",
    "\n",
    "        # 写类别名称和置信度\n",
    "        # 图片，添加的文字，左上角坐标，字体，字体大小，颜色，字体粗细\n",
    "        string = '{} {}'.format(class_names[i], confidence)\n",
    "        cv2.putText(img, string, (x, y+20), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),5)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 视频逐帧处理（模板）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 视频逐帧处理代码模板\n",
    "# 不需修改任何代码，只需定义process_frame函数即可\n",
    "# 同济子豪兄 2021-7-10\n",
    "\n",
    "def generate_video(input_path='./videos/three-hands.mp4'):\n",
    "    filehead = input_path.split('/')[-1]\n",
    "    output_path = \"out-\" + filehead\n",
    "    \n",
    "    print('视频开始处理',input_path)\n",
    "    \n",
    "    # 获取视频总帧数\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    frame_count = 0\n",
    "    while(cap.isOpened()):\n",
    "        success, frame = cap.read()\n",
    "        frame_count += 1\n",
    "        if not success:\n",
    "            break\n",
    "    cap.release()\n",
    "    print('视频总帧数为',frame_count)\n",
    "    \n",
    "    # cv2.namedWindow('Crack Detection and Measurement Video Processing')\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    frame_size = (cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # fourcc = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (int(frame_size[0]), int(frame_size[1])))\n",
    "    \n",
    "    # 进度条绑定视频总帧数\n",
    "    with tqdm(total=frame_count-1) as pbar:\n",
    "        try:\n",
    "            while(cap.isOpened()):\n",
    "                success, frame = cap.read()\n",
    "                if not success:\n",
    "                    break\n",
    "\n",
    "                # 处理帧\n",
    "                # frame_path = './temp_frame.png'\n",
    "                # cv2.imwrite(frame_path, frame)\n",
    "                try:\n",
    "                    frame = process_frame(frame)\n",
    "                except Exception as e:\n",
    "                    print('error',e)\n",
    "                    pass\n",
    "                \n",
    "                if success == True:\n",
    "                    # cv2.imshow('Video Processing', frame)\n",
    "                    out.write(frame)\n",
    "\n",
    "                    # 进度条更新一帧\n",
    "                    pbar.update(1)\n",
    "\n",
    "                # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    # break\n",
    "        except:\n",
    "            print('中途中断')\n",
    "            pass\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    out.release()\n",
    "    cap.release()\n",
    "    print('视频已保存', output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generate_video(input_path='test-video.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3caf13703c5b1c02abff9fa597e671e1239d1d668b6a345ae62ddadff9d8fc63"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('py37': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}